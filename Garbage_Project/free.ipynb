{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('maskrcnn_model_def.txt') as f:\n",
    "    modeltxt = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def_list=[]\n",
    "while modeltxt.find('def')!=-1:\n",
    "    starts=modeltxt.find('def')\n",
    "    modeltxt = modeltxt[starts:]\n",
    "    ends=modeltxt.find(':\\n')\n",
    "    def_list.append(modeltxt[:ends+1])\n",
    "    modeltxt=modeltxt[ends+2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def log(text, array=None):',\n",
       " 'def call(self, inputs, training=None):',\n",
       " 'def compute_backbone_shapes(config, image_shape):',\n",
       " 'def identity_block(input_tensor, kernel_size, filters, stage, block,\\n                   use_bias=True, train_bn=True):',\n",
       " 'default 3, the kernel size of middle conv layer at main path\\n        filters: list of integers, the nb_filters of 3 conv layer at main path\\n        stage: integer, current stage label, used for generating layer names\\n        block: \\'a\\',\\'b\\'..., current block label, used for generating layer names\\n        use_bias: Boolean. To use or not use a bias in conv layers.\\n        train_bn: Boolean. Train or freeze Batch Norm layers\\n    \"\"\"\\n    nb_filter1, nb_filter2, nb_filter3 = filters\\n    conv_name_base = \\'res\\' + str(stage) + block + \\'_branch\\'\\n    bn_name_base = \\'bn\\' + str(stage) + block + \\'_branch\\'\\n\\n    x = KL.Conv2D(nb_filter1, (1, 1), name=conv_name_base + \\'2a\\',\\n                  use_bias=use_bias)(input_tensor)\\n    x = BatchNorm(name=bn_name_base + \\'2a\\')(x, training=train_bn)\\n    x = KL.Activation(\\'relu\\')(x)\\n\\n    x = KL.Conv2D(nb_filter2, (kernel_size, kernel_size), padding=\\'same\\',\\n                  name=conv_name_base + \\'2b\\', use_bias=use_bias)(x)\\n    x = BatchNorm(name=bn_name_base + \\'2b\\')(x, training=train_bn)\\n    x = KL.Activation(\\'relu\\')(x)\\n\\n    x = KL.Conv2D(nb_filter3, (1, 1), name=conv_name_base + \\'2c\\',\\n                  use_bias=use_bias)(x)\\n    x = BatchNorm(name=bn_name_base + \\'2c\\')(x, training=train_bn)\\n\\n    x = KL.Add()([x, input_tensor])\\n    x = KL.Activation(\\'relu\\', name=\\'res\\' + str(stage) + block + \\'_out\\')(x)\\n    return x\\n\\n\\ndef conv_block(input_tensor, kernel_size, filters, stage, block,\\n               strides=(2, 2), use_bias=True, train_bn=True):',\n",
       " 'default 3, the kernel size of middle conv layer at main path\\n        filters: list of integers, the nb_filters of 3 conv layer at main path\\n        stage: integer, current stage label, used for generating layer names\\n        block: \\'a\\',\\'b\\'..., current block label, used for generating layer names\\n        use_bias: Boolean. To use or not use a bias in conv layers.\\n        train_bn: Boolean. Train or freeze Batch Norm layers\\n    Note that from stage 3, the first conv layer at main path is with subsample=(2,2)\\n    And the shortcut should have subsample=(2,2) as well\\n    \"\"\"\\n    nb_filter1, nb_filter2, nb_filter3 = filters\\n    conv_name_base = \\'res\\' + str(stage) + block + \\'_branch\\'\\n    bn_name_base = \\'bn\\' + str(stage) + block + \\'_branch\\'\\n\\n    x = KL.Conv2D(nb_filter1, (1, 1), strides=strides,\\n                  name=conv_name_base + \\'2a\\', use_bias=use_bias)(input_tensor)\\n    x = BatchNorm(name=bn_name_base + \\'2a\\')(x, training=train_bn)\\n    x = KL.Activation(\\'relu\\')(x)\\n\\n    x = KL.Conv2D(nb_filter2, (kernel_size, kernel_size), padding=\\'same\\',\\n                  name=conv_name_base + \\'2b\\', use_bias=use_bias)(x)\\n    x = BatchNorm(name=bn_name_base + \\'2b\\')(x, training=train_bn)\\n    x = KL.Activation(\\'relu\\')(x)\\n\\n    x = KL.Conv2D(nb_filter3, (1, 1), name=conv_name_base +\\n                  \\'2c\\', use_bias=use_bias)(x)\\n    x = BatchNorm(name=bn_name_base + \\'2c\\')(x, training=train_bn)\\n\\n    shortcut = KL.Conv2D(nb_filter3, (1, 1), strides=strides,\\n                         name=conv_name_base + \\'1\\', use_bias=use_bias)(input_tensor)\\n    shortcut = BatchNorm(name=bn_name_base + \\'1\\')(shortcut, training=train_bn)\\n\\n    x = KL.Add()([x, shortcut])\\n    x = KL.Activation(\\'relu\\', name=\\'res\\' + str(stage) + block + \\'_out\\')(x)\\n    return x\\n\\n\\ndef resnet_graph(input_image, architecture, stage5=False, train_bn=True):',\n",
       " 'def apply_box_deltas_graph(boxes, deltas):',\n",
       " 'def clip_boxes_graph(boxes, window):',\n",
       " 'def __init__(self, proposal_count, nms_threshold, config=None, **kwargs):',\n",
       " 'def get_config(self):',\n",
       " 'def call(self, inputs):',\n",
       " 'def nms(boxes, scores):',\n",
       " 'def compute_output_shape(self, input_shape):',\n",
       " 'def log2_graph(x):',\n",
       " 'def __init__(self, pool_shape, **kwargs):',\n",
       " 'def get_config(self):',\n",
       " 'def call(self, inputs):',\n",
       " 'def compute_output_shape(self, input_shape):',\n",
       " 'def overlaps_graph(boxes1, boxes2):',\n",
       " 'def detection_targets_graph(proposals, gt_class_ids, gt_boxes, gt_masks, config):',\n",
       " 'def __init__(self, config, **kwargs):',\n",
       " 'def get_config(self):',\n",
       " 'def call(self, inputs):',\n",
       " 'def compute_output_shape(self, input_shape):',\n",
       " 'def compute_mask(self, inputs, mask=None):',\n",
       " 'def refine_detections_graph(rois, probs, deltas, window, config):',\n",
       " 'def nms_keep_map(class_id):',\n",
       " 'def __init__(self, config=None, **kwargs):',\n",
       " 'def get_config(self):',\n",
       " 'def call(self, inputs):',\n",
       " 'def compute_output_shape(self, input_shape):',\n",
       " 'def rpn_graph(feature_map, anchors_per_location, anchor_stride):',\n",
       " 'def build_rpn_model(anchor_stride, anchors_per_location, depth):',\n",
       " 'def fpn_classifier_graph(rois, feature_maps, image_meta,\\n                         pool_size, num_classes, train_bn=True,\\n                         fc_layers_size=1024):',\n",
       " 'def build_fpn_mask_graph(rois, feature_maps, image_meta,\\n                         pool_size, num_classes, train_bn=True):',\n",
       " 'def smooth_l1_loss(y_true, y_pred):',\n",
       " 'def rpn_class_loss_graph(rpn_match, rpn_class_logits):',\n",
       " 'def rpn_bbox_loss_graph(config, target_bbox, rpn_match, rpn_bbox):',\n",
       " 'def mrcnn_class_loss_graph(target_class_ids, pred_class_logits,\\n                           active_class_ids):',\n",
       " 'def mrcnn_bbox_loss_graph(target_bbox, target_class_ids, pred_bbox):',\n",
       " 'def mrcnn_mask_loss_graph(target_masks, target_class_ids, pred_masks):',\n",
       " 'def load_image_gt(dataset, config, image_id, augmentation=None):',\n",
       " 'defined in MINI_MASK_SHAPE.\\n    \"\"\"\\n    # Load image and mask\\n    image = dataset.load_image(image_id)\\n    mask, class_ids = dataset.load_mask(image_id)\\n    original_shape = image.shape\\n    image, window, scale, padding, crop = utils.resize_image(\\n        image,\\n        min_dim=config.IMAGE_MIN_DIM,\\n        min_scale=config.IMAGE_MIN_SCALE,\\n        max_dim=config.IMAGE_MAX_DIM,\\n        mode=config.IMAGE_RESIZE_MODE)\\n    mask = utils.resize_mask(mask, scale, padding, crop)\\n\\n    # Augmentation\\n    # This requires the imgaug lib (https://github.com/aleju/imgaug)\\n    if augmentation:',\n",
       " 'def hook(images, augmenter, parents, default):',\n",
       " 'def build_detection_targets(rpn_rois, gt_class_ids, gt_boxes, gt_masks, config):',\n",
       " 'def build_rpn_targets(image_shape, anchors, gt_class_ids, gt_boxes, config):',\n",
       " 'def generate_random_rois(image_shape, count, gt_class_ids, gt_boxes):',\n",
       " 'defined in MINI_MASK_SHAPE.\\n\\n        outputs list: Usually empty in regular training. But if detection_targets\\n            is True then the outputs list contains target class_ids, bbox deltas,\\n            and masks.\\n        \"\"\"\\n\\n    def __init__(self, dataset, config, shuffle=True, augmentation=None,\\n                 random_rois=0, detection_targets=False):',\n",
       " 'def __len__(self):',\n",
       " 'def __getitem__(self, idx):',\n",
       " 'def __init__(self, mode, config, model_dir):',\n",
       " 'def build(self, mode, config):',\n",
       " 'def __init__(self, x, name=None):',\n",
       " 'def call(self, input):',\n",
       " 'def find_last(self):',\n",
       " 'def load_weights(self, filepath, by_name=False, exclude=None):',\n",
       " 'def get_imagenet_weights(self):',\n",
       " 'def compile(self, learning_rate, momentum):',\n",
       " 'def set_trainable(self, layer_regex, keras_model=None, indent=0, verbose=1):',\n",
       " 'def set_log_dir(self, model_path=None):',\n",
       " 'def train(self, train_dataset, val_dataset, learning_rate, epochs, layers,\\n              augmentation=None, custom_callbacks=None, no_augmentation_sources=None):',\n",
       " 'defined values:',\n",
       " 'defined in the Dataset class.\\n        \"\"\"\\n        assert self.mode == \"training\", \"Create model in training mode.\"\\n\\n        # Pre-defined layer regular expressions\\n        layer_regex = {\\n            # all layers but the backbone\\n            \"heads\": r\"(mrcnn\\\\_.*)|(rpn\\\\_.*)|(fpn\\\\_.*)\",\\n            # From a specific Resnet stage and up\\n            \"3+\": r\"(res3.*)|(bn3.*)|(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\\\_.*)|(rpn\\\\_.*)|(fpn\\\\_.*)\",\\n            \"4+\": r\"(res4.*)|(bn4.*)|(res5.*)|(bn5.*)|(mrcnn\\\\_.*)|(rpn\\\\_.*)|(fpn\\\\_.*)\",\\n            \"5+\": r\"(res5.*)|(bn5.*)|(mrcnn\\\\_.*)|(rpn\\\\_.*)|(fpn\\\\_.*)\",\\n            # All layers\\n            \"all\": \".*\",\\n        }\\n        if layers in layer_regex.keys():',\n",
       " 'def mold_inputs(self, images):',\n",
       " 'def unmold_detections(self, detections, mrcnn_mask, original_image_shape,\\n                          image_shape, window):',\n",
       " 'def detect(self, images, verbose=0):',\n",
       " 'def detect_molded(self, molded_images, image_metas, verbose=0):',\n",
       " 'def get_anchors(self, image_shape):',\n",
       " 'def ancestor(self, tensor, name, checked=None):',\n",
       " 'def find_trainable_layer(self, layer):',\n",
       " 'def get_trainable_layers(self):',\n",
       " 'def run_graph(self, images, outputs, image_metas=None):',\n",
       " 'def compose_image_meta(image_id, original_image_shape, image_shape,\\n                       window, scale, active_class_ids):',\n",
       " 'def parse_image_meta(meta):',\n",
       " 'def parse_image_meta_graph(meta):',\n",
       " 'def mold_image(images, config):',\n",
       " 'def unmold_image(normalized_images, config):',\n",
       " \"def trim_zeros_graph(boxes, name='trim_zeros'):\",\n",
       " 'def batch_pack_graph(x, counts, num_rows):',\n",
       " 'def norm_boxes_graph(boxes, shape):',\n",
       " 'def denorm_boxes_graph(boxes, shape):']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('def_list.txt','w') as f:\n",
    "    for i in def_list:\n",
    "        f.write(i + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=1\n",
    "callable(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
